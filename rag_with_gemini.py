#!/usr/bin/env python3
"""
rag_with_gemini.py

RAG pipeline dÃ¹ng:
- Qdrant (retriever, vector DB)
- SentenceTransformers (CLIP-ViT-B-32) Ä‘á»ƒ embed cÃ¢u truy váº¥n
- Gemini API Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i cháº©n Ä‘oÃ¡n y khoa

ğŸ‘‰ Báº¡n chá»‰ cáº§n Ä‘á»•i GEMINI_API_KEY bÃªn dÆ°á»›i khi háº¿t lÆ°á»£t.
"""

import os
import sys
import textwrap
from typing import List, Dict, Any
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
from google import genai

# -----------------------
# ğŸ”§ Cáº¥u hÃ¬nh chÃ­nh
# -----------------------
QDRANT_URL = "http://localhost:6333"
COLLECTION_NAME = "tropical_disease_cases_mm"
EMBED_MODEL_NAME = "clip-ViT-B-32"
GEMINI_MODEL = "gemini-2.5-flash"

# âš ï¸ ğŸ‘‰ ThÃªm key thá»§ cÃ´ng á»Ÿ Ä‘Ã¢y
GEMINI_API_KEY = "AIzaSyDDvw6S5PQVCYmmRSxZEP97ZgWnbzvD1PA"

if not GEMINI_API_KEY or GEMINI_API_KEY.strip() == "":
    print("âŒ Báº¡n chÆ°a thÃªm GEMINI_API_KEY. Vui lÃ²ng thÃªm key trong file nÃ y rá»“i cháº¡y láº¡i.")
    sys.exit(1)

# -----------------------
# ğŸš€ Khá»Ÿi táº¡o client
# -----------------------
print("ğŸ”— Connecting to Qdrant and Gemini...")
qdrant = QdrantClient(url=QDRANT_URL)
embedder = SentenceTransformer(EMBED_MODEL_NAME)
genai_client = genai.Client(api_key=GEMINI_API_KEY)

# -----------------------
# âš™ï¸ HÃ m tiá»‡n Ã­ch
# -----------------------
def retrieve_top_k(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """Láº¥y top-k káº¿t quáº£ tÆ°Æ¡ng tá»± tá»« Qdrant."""
    q_vec = embedder.encode(query).tolist()
    hits = qdrant.search(collection_name=COLLECTION_NAME, query_vector=q_vec, limit=top_k)
    results = []
    for h in hits:
        payload = h.payload or {}
        results.append({
            "score": getattr(h, "score", None),
            "payload": payload
        })
    return results

def build_context_snippets(hits: List[Dict[str, Any]], max_chars: int = 3500) -> str:
    """GhÃ©p cÃ¡c Ä‘oáº¡n mÃ´ táº£ case thÃ nh context cho prompt."""
    parts = []
    total_len = 0
    for i, hit in enumerate(hits, start=1):
        payload = hit["payload"]
        case_id = payload.get("case_id") or payload.get("id") or f"unknown-{i}"
        text_field = payload.get("text") or payload.get("final_diagnosis") or payload.get("management_and_clinical_course") or ""
        snippet = text_field.strip().replace("\n", " ")
        if len(snippet) > 600:
            snippet = snippet[:590] + " ..."
        entry_lines = [f"--- Case {case_id} (score={hit.get('score'):.4f}):"]
        if snippet:
            entry_lines.append(f"Text snippet: {snippet}")
        if payload.get("image_path"):
            entry_lines.append(f"Image path: {payload['image_path']}")
        elif payload.get("images"):
            imgs = payload["images"]
            if isinstance(imgs, list) and imgs:
                entry_lines.append(f"Image path: {imgs[0]}")
        entry_text = " ".join(entry_lines)
        if total_len + len(entry_text) > max_chars:
            break
        parts.append(entry_text)
        total_len += len(entry_text)
    return "\n\n".join(parts) if parts else "No relevant context found."

def build_prompt(context: str, question: str) -> str:
    """Táº¡o prompt hoÃ n chá»‰nh gá»­i Ä‘áº¿n Gemini."""
    system = (
        "You are a medical assistant specialized in tropical infectious diseases. "
        "Use the context from clinical case reports below to suggest possible diagnoses and management plans. "
        "If uncertain, state what information is missing."
    )
    prompt = textwrap.dedent(f"""
    SYSTEM INSTRUCTION:
    {system}

    CONTEXT:
    {context}

    USER QUESTION:
    {question}

    Please answer concisely in 3 parts:
    1. Summary (1â€“2 sentences)
    2. Likely diagnosis (brief reasoning)
    3. Suggested next diagnostic steps or management.
    """).strip()
    return prompt

def call_gemini(prompt: str) -> str:
    """Gá»­i prompt Ä‘áº¿n Gemini vÃ  tráº£ vá» pháº£n há»“i."""
    try:
        response = genai_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"âŒ Lá»—i khi gá»i Gemini API: {e}"

# -----------------------
# ğŸ’¬ Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c
# -----------------------
def interactive_loop():
    print("\n=== ğŸ§  Tropical Disease Diagnosis (RAG + Gemini) ===")
    print("Nháº­p mÃ´ táº£ triá»‡u chá»©ng hoáº·c cÃ¢u há»i. GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.")
    while True:
        question = input("\nğŸ” CÃ¢u há»i: ").strip()
        if not question:
            continue
        if question.lower() in ("exit", "quit"):
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break

        print("\nğŸ” Äang truy xuáº¥t dá»¯ liá»‡u liÃªn quan tá»« Qdrant...")
        hits = retrieve_top_k(question)
        if not hits:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y case nÃ o phÃ¹ há»£p.")
            continue

        print(f"âœ… TÃ¬m tháº¥y {len(hits)} case tÆ°Æ¡ng tá»±.")
        context = build_context_snippets(hits)
        prompt = build_prompt(context, question)

        print("\nğŸ¤– Äang gá»i Gemini Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i...")
        answer = call_gemini(prompt)
        print("\n================= ğŸ©º Káº¾T QUáº¢ =================\n")
        print(answer)
        print("\n==============================================")

if __name__ == "__main__":
    try:
        interactive_loop()
    except KeyboardInterrupt:
        print("\nğŸšª Dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng. Táº¡m biá»‡t!")
